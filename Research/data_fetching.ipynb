{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection for Database\n",
    "1. Stock Data: Stock List [NASDAQ-100], General Information, Fundamental data, Yearly Data, Intraday Data, Analyst Ratings]\n",
    "2. Sentiment Data: Using Vader for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import yahoo_fin.stock_info as si\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock list\n",
    "def fetch_stock_list():\n",
    "    url = \"https://api.nasdaq.com/api/quote/list-type/nasdaq100\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36', \"Upgrade-Insecure-Requests\": \"1\",\"DNT\": \"1\",\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\"Accept-Language\": \"en-US,en;q=0.5\",\"Accept-Encoding\": \"gzip, deflate\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    stock_list = [item[\"symbol\"] for item in data[\"data\"][\"data\"][\"rows\"]]\n",
    "    return stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name, sector, industry, description\n",
    "def stock_general_info(ticker):\n",
    "\n",
    "    # name, sector, industry - yahoo finance\n",
    "    url = f\"https://finance.yahoo.com/quote/{ticker}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    name = soup.find(\"h1\", class_=\"D(ib)\").text\n",
    "    sector = soup.find(\"span\", text=\"Sector(s)\").find_next_sibling(\"span\").text\n",
    "    industry = soup.find(\"span\", text=\"Industry\").find_next_sibling(\"span\").text\n",
    "\n",
    "    # general info - marketwatch\n",
    "    url = f\"https://www.marketwatch.com/investing/stock/{ticker}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    description = soup.find(\"p\", class_=\"description__text\").text.strip()\n",
    "    \n",
    "\n",
    "    return (name,sector,industry,description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fundamental ratios and data\n",
    "def fundamental_data(ticker):\n",
    "    data = si.get_quote_table(ticker)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly prices\n",
    "def yearly_prices(ticker):\n",
    "    data = yf.download(ticker, period=\"1y\", interval=\"1d\")\n",
    "    return data[['Adj Close']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intraday prices\n",
    "def intraday_prices(ticker):\n",
    "    data = yf.download(ticker, period=\"1d\", interval=\"2m\")\n",
    "    return data[['Adj Close']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "def find_sentiment(ticker):\n",
    "    url = f'https://finviz.com/quote.ashx?t={ticker}'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, features='html.parser')\n",
    "    news_table = soup.find(id='news-table')\n",
    "\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = []\n",
    "    for row in news_table.findAll('tr'):\n",
    "        date_data = row.td.text.split(' ')\n",
    "        if len(date_data) == 1:\n",
    "            date = date\n",
    "            time = date_data[0]\n",
    "        else:\n",
    "            date = date_data[0]\n",
    "            time = date_data[1]\n",
    "        headline = row.a.text\n",
    "        print(headline)\n",
    "        sentiment_score = analyzer.polarity_scores(headline)['compound']\n",
    "        sentiment_scores.append(sentiment_score)\n",
    "\n",
    "\n",
    "    overall_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "    return(overall_sentiment_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
